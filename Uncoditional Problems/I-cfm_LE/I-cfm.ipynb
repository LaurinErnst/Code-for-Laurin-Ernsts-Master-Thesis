{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchcfm.optimal_transport import OTPlanSampler\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ot as pot\n",
    "import torch\n",
    "import torchdyn\n",
    "from torchdyn.core import NeuralODE\n",
    "from torchcfm.conditional_flow_matching import *\n",
    "from torchcfm.models.models import *\n",
    "from torchcfm.utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "distance = 0.4\n",
    "sample_multiplier = 10\n",
    "# 16\n",
    "# for i in np.arange(0, 8, distance):\n",
    "#     for j in np.arange(0, 2, distance):\n",
    "#         x.append([j, i])\n",
    "for i in range(16 * sample_multiplier):\n",
    "    x.append([np.random.uniform(0, 2), np.random.uniform(0, 8)])\n",
    "\n",
    "# 4\n",
    "# for i in np.arange(0, 2, distance):\n",
    "#     for j in np.arange(2, 6, distance):\n",
    "#         x.append([j, i])\n",
    "for i in range(4 * sample_multiplier):\n",
    "    x.append([np.random.uniform(2, 4), np.random.uniform(0, 2)])\n",
    "\n",
    "\n",
    "# 16\n",
    "# for i in np.arange(0, 8, distance):\n",
    "#     for j in np.arange(10, 12, distance):\n",
    "#         x.append([j, i])\n",
    "for i in range(16 * sample_multiplier):\n",
    "    x.append([np.random.uniform(10, 12), np.random.uniform(0, 8)])\n",
    "\n",
    "# 8\n",
    "# for i in np.arange(6, 8, distance):\n",
    "#     for j in np.arange(12, 16, distance):\n",
    "#         x.append([j, i])\n",
    "for i in range(8 * sample_multiplier):\n",
    "    x.append([np.random.uniform(12, 16), np.random.uniform(6, 8)])\n",
    "\n",
    "# 8\n",
    "# for i in np.arange(3, 5, distance):\n",
    "#     for j in np.arange(12, 16, distance):\n",
    "#         x.append([j, i])\n",
    "for i in range(8 * sample_multiplier):\n",
    "    x.append([np.random.uniform(12, 16), np.random.uniform(3, 5)])\n",
    "\n",
    "# 8\n",
    "# for i in np.arange(0, 2, distance):\n",
    "#     for j in np.arange(12, 16, distance):\n",
    "#         x.append([j, i])\n",
    "for i in range(8 * sample_multiplier):\n",
    "    x.append([np.random.uniform(12, 16), np.random.uniform(0, 2)])\n",
    "\n",
    "x = torch.tensor(x)\n",
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_conditional_pt(x0, x1, t, sigma):\n",
    "    \"\"\"\n",
    "    Draw a sample from the probability path N(t * x1 + (1 - t) * x0, sigma), see (Eq.14) [1].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x0 : Tensor, shape (bs, *dim)\n",
    "        represents the source minibatch\n",
    "    x1 : Tensor, shape (bs, *dim)\n",
    "        represents the target minibatch\n",
    "    t : FloatTensor, shape (bs)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xt : Tensor, shape (bs, *dim)\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [1] Improving and Generalizing Flow-Based Generative Models with minibatch optimal transport, Preprint, Tong et al.\n",
    "    \"\"\"\n",
    "    t = t.reshape(-1, *([1] * (x0.dim() - 1)))\n",
    "    mu_t = t * x1 + (1 - t) * x0\n",
    "    epsilon = torch.randn_like(x0)\n",
    "    return mu_t + sigma * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conditional_vector_field(x0, x1):\n",
    "    \"\"\"\n",
    "    Compute the conditional vector field ut(x1|x0) = x1 - x0, see Eq.(15) [1].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x0 : Tensor, shape (bs, *dim)\n",
    "        represents the source minibatch\n",
    "    x1 : Tensor, shape (bs, *dim)\n",
    "        represents the target minibatch\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ut : conditional vector field ut(x1|x0) = x1 - x0\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [1] Improving and Generalizing Flow-Based Generative Models with minibatch optimal transport, Preprint, Tong et al.\n",
    "    \"\"\"\n",
    "    return x1 - x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD(x, y):\n",
    "        gamma = 2\n",
    "        xx, yy, zz = torch.mm(x, x.t()), torch.mm(y, y.t()), torch.mm(x, y.t())\n",
    "        rx = (xx.diag().unsqueeze(0).expand_as(xx))\n",
    "        ry = (yy.diag().unsqueeze(0).expand_as(yy))\n",
    "\n",
    "        dxx = rx.t() + rx - 2. * xx # Used for A in (1)\n",
    "        dyy = ry.t() + ry - 2. * yy # Used for B in (1)\n",
    "        rxx = rx[0].repeat(y.shape[0], 1)\n",
    "        ryy = ry[0].repeat(x.shape[0], 1) \n",
    "        dxy = rxx.t() + ryy - 2. * zz # Used for C in (1)\n",
    "\n",
    "        XX, YY, XY = (torch.zeros(xx.shape).to(device),\n",
    "                      torch.zeros(yy.shape).to(device),\n",
    "                      torch.zeros(zz.shape).to(device))\n",
    "        XX += 1/(1 + dxx/gamma**2)\n",
    "        YY += 1/(1 + dyy/gamma**2)\n",
    "        XY += 1/(1 + dxy/gamma**2)\n",
    "        return XX.mean() + YY.mean() - 2*XY.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000: loss 5.726 time 15.49\n",
      "2000: loss 5.195 time 22.07\n",
      "3000: loss 5.817 time 16.51\n",
      "4000: loss 6.632 time 16.67\n",
      "5000: loss 5.395 time 17.04\n"
     ]
    }
   ],
   "source": [
    "f = open(\"results.txt\", \"w\")\n",
    "for i in [128]:\n",
    "    for j in [8]:\n",
    "        loss_arr = []\n",
    "        f.write(\"OTFlow layers: \" + str(j) + \" width: \" + str(i) + \"\\n\")\n",
    "        ot_sampler = OTPlanSampler(method=\"exact\")\n",
    "        sigma = 1e-8\n",
    "        dim = 2\n",
    "        batch_size = 256\n",
    "        if j == 2:\n",
    "            model = torch.nn.Sequential(\n",
    "                torch.nn.Linear(dim + 1, i),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(i, dim),\n",
    "            )\n",
    "        if j == 4:\n",
    "            model = torch.nn.Sequential(\n",
    "                torch.nn.Linear(dim + 1, i),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(i, i),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(i, i),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(i, dim),\n",
    "            )\n",
    "        if j == 8:\n",
    "            model = torch.nn.Sequential(\n",
    "                torch.nn.Linear(dim + 1, i),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(i, i),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(i, i),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(i, i),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(i, i),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(i, i),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(i, i),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(i, dim),\n",
    "            )\n",
    "        #_______________\n",
    "        num_dims = 2\n",
    "        node = NeuralODE(\n",
    "                torch_wrapper(model), solver=\"dopri5\", sensitivity=\"adjoint\", atol=1e-4, rtol=1e-4\n",
    "            )\n",
    "        with torch.no_grad():\n",
    "            traj = node.trajectory(\n",
    "                torch.tensor(np.random.normal([0] * num_dims, 1, size=(x.shape[0], num_dims))).float().to(device),\n",
    "                t_span=torch.linspace(0, 1, 100),\n",
    "            )\n",
    "        f.write(\"MMD before training: \" + str(MMD(traj[-1, :, :], x).item()) + \"\\n\")\n",
    "        #_______________\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "        FM = ConditionalFlowMatcher(sigma=sigma)\n",
    "\n",
    "        dataloader = torch.utils.data.DataLoader(x, batch_size=int(x.shape[0]), shuffle=True)\n",
    "\n",
    "        start = time.time()\n",
    "        for k in range(5000):\n",
    "            for x_batch in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                x1 = x_batch.to(device)\n",
    "                x0 = torch.tensor(np.random.normal([0] * num_dims, 1, size=(len(x1), num_dims))).to(device)\n",
    "\n",
    "\n",
    "                t = torch.rand(x0.shape[0]).type_as(x0)\n",
    "                xt = sample_conditional_pt(x0, x1, t, sigma=sigma).float()\n",
    "                ut = compute_conditional_vector_field(x0, x1)\n",
    "\n",
    "                vt = model(torch.cat([xt, t[:, None]], dim=-1).float())\n",
    "                loss = torch.mean((vt - ut) ** 2)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_arr.append(loss.item())\n",
    "\n",
    "            if (k + 1) % 1000 == 0:\n",
    "                end = time.time()\n",
    "                print(f\"{k+1}: loss {loss.item():0.3f} time {(end - start):0.2f}\")\n",
    "                start = end\n",
    "\n",
    "        np.savetxt(\"l\"+str(j) + \"w\" + str(i) + \".txt\", loss_arr, fmt='%f')\n",
    "        node = NeuralODE(\n",
    "            torch_wrapper(model), solver=\"dopri5\", sensitivity=\"adjoint\", atol=1e-4, rtol=1e-4\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            traj = node.trajectory(\n",
    "                torch.tensor(np.random.normal([0] * num_dims, 1, size=(x.shape[0], num_dims))).float().to(device),\n",
    "                t_span=torch.linspace(0, 1, 100),\n",
    "            )\n",
    "        f.write(\"MMD after training: \" + str(MMD(traj[-1, :, :], x).item()) + \"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        node = NeuralODE(\n",
    "            torch_wrapper(model), solver=\"dopri5\", sensitivity=\"adjoint\", atol=1e-4, rtol=1e-4\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            traj = node.trajectory(\n",
    "                torch.tensor(np.random.normal([0] * num_dims, 1, size=(10000, num_dims))).float().to(device),\n",
    "                t_span=torch.linspace(0, 1, 100),\n",
    "            )\n",
    "        traj = traj.cpu().numpy()\n",
    "        n = 1000\n",
    "        col_red = '#c61826'\n",
    "        col_dark_red = '#590d08'\n",
    "        col_blue = '#01024d'\n",
    "        plt.figure()\n",
    "        plt.scatter(traj[:, :n, 0], traj[:, :n, 1], s=0.1, alpha=0.1, c=col_dark_red)\n",
    "        plt.scatter(traj[0, :n, 0], traj[0, :n, 1], s=5, alpha=0.8, c=col_blue)\n",
    "        plt.scatter(traj[-1, :n, 0], traj[-1, :n, 1], s=5, alpha=1, c=col_red)\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Y\")\n",
    "        plt.ylim(-5, 10)\n",
    "        plt.xlim(-5, 18)\n",
    "        plt.savefig(\"ICfm_plot_LE_gen_l\" + str(j) + \"w\" + str(i) + \".png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.scatter(x[:, 0], x[:, 1], alpha = 1, s=25, label=\"Original Data\", c = col_blue)\n",
    "        plt.scatter(traj[-1, :n, 0], traj[-1, :n, 1], s=25, alpha=1, label=\"Generated Data\", c=col_red)\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Y\")\n",
    "        plt.ylim(-5, 10)\n",
    "        plt.xlim(-5, 18)\n",
    "        plt.legend()\n",
    "        plt.savefig(\"ICfm_plot_LE_gen_smp_l\" + str(j) + \"w\" + str(i) + \".png\")\n",
    "        plt.close()\n",
    "\n",
    "        # plt.legend()\n",
    "        # plt.figure()\n",
    "        # plt.semilogy(loss_arr)\n",
    "        # plt.xlabel(\"Epochs\")\n",
    "        # plt.ylabel(\"Log Log Likelihood Loss\")\n",
    "        # plt.ylim(1e-8, 450)\n",
    "        # plt.savefig(\"semilog_loss_plot_l\" + str(j) + \"w\" + str(i) + \".png\")\n",
    "        plt.close()\n",
    "        plt.figure()\n",
    "        plt.plot(loss_arr)\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Flow Matching Loss\")\n",
    "        plt.ylim(0, 20)\n",
    "        plt.savefig(\"ICfm_LE_loss_plot_l\" + str(j) + \"w\" + str(i) + \".png\")\n",
    "        plt.close()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
